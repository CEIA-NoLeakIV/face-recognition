{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face-Recognition Training\n",
    "Este notebook tem como objetivo treinar os modelos presentes dentro do framework face-recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import das bibliotecas e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "\n",
    "sys.path.append('../../src/models/face-recognition')\n",
    "from train import main, parse_arguments\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar parâmetros de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Dataset: VggFace2 from ../../data/raw/vggface2_112x112/\n",
      "Model: mobilenetv2 with MCP classifier\n",
      "Batch size: 64, Epochs: 1\n",
      "Learning rate: 0.001, Scheduler: MultiStepLR\n",
      "Save path: ../../src/models/face-recognition/weights\n",
      "LFW path: ../../data/raw/lfw\n"
     ]
    }
   ],
   "source": [
    "# Configurar parâmetros de treinamento\n",
    "root_path = \"../../data/raw/vggface2_112x112/\"  # Caminho para o dataset de treinamento\n",
    "database = \"VggFace2\"  # Opções: WebFace, VggFace2, MS1M\n",
    "\n",
    "# Configuração do modelo\n",
    "network = \"mobilenetv2\"  # Opções: sphere20, sphere36, sphere64, mobilenetv1, mobilenetv2, mobilenetv3_small, mobilenetv3_large\n",
    "classifier = \"MCP\"  # Opções: ARC (ArcFace), MCP (MarginCosineProduct), AL (SphereFace), L (Linear)\n",
    "\n",
    "# Hiperparâmetros de treinamento\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = \"MultiStepLR\"  # Opções: StepLR, MultiStepLR\n",
    "milestones = [10, 20, 25]  # For MultiStepLR\n",
    "step_size = 10  # For StepLR\n",
    "gamma = 0.1  # Decay factor\n",
    "\n",
    "# Configurações adicionais\n",
    "save_path = \"../../src/models/face-recognition/weights\"\n",
    "lfw_dataset_path = \"../../data/raw/lfw\"\n",
    "num_workers = 8\n",
    "print_freq = 10000\n",
    "checkpoint_path = None  # Definir se quiser retomar o treinamento de um checkpoint\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Dataset: {database} from {root_path}\")\n",
    "print(f\"Model: {network} with {classifier} classifier\")\n",
    "print(f\"Batch size: {batch_size}, Epochs: {epochs}\")\n",
    "print(f\"Learning rate: {learning_rate}, Scheduler: {lr_scheduler}\")\n",
    "print(f\"Save path: {save_path}\")\n",
    "print(f\"LFW path: {lfw_dataset_path}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opções compatíveis (apenas p/ referência)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: ['sphere20', 'sphere36', 'sphere64', 'mobilenetv1', 'mobilenetv2', 'mobilenetv3_small', 'mobilenetv3_large']\n",
      "Available Databases: ['WebFace', 'VggFace2', 'MS1M']\n",
      "Available Classifiers: ['ARC', 'MCP', 'AL', 'L']\n",
      "Available Schedulers: ['StepLR', 'MultiStepLR']\n",
      "\n",
      "Selected database 'VggFace2' has 8631 classes\n"
     ]
    }
   ],
   "source": [
    "# Opções compatíveis (apenas p/ referência)\n",
    "available_models = [\n",
    "    \"sphere20\", \"sphere36\", \"sphere64\",\n",
    "    \"mobilenetv1\", \"mobilenetv2\", \n",
    "    \"mobilenetv3_small\", \"mobilenetv3_large\"\n",
    "]\n",
    "\n",
    "available_databases = [\"WebFace\", \"VggFace2\", \"MS1M\"]\n",
    "available_classifiers = [\"ARC\", \"MCP\", \"AL\", \"L\"]\n",
    "available_schedulers = [\"StepLR\", \"MultiStepLR\"]\n",
    "\n",
    "print(\"Available Models:\", available_models)\n",
    "print(\"Available Databases:\", available_databases)\n",
    "print(\"Available Classifiers:\", available_classifiers)\n",
    "print(\"Available Schedulers:\", available_schedulers)\n",
    "\n",
    "# Database info\n",
    "db_info = {\n",
    "    'WebFace': {'num_classes': 10572},\n",
    "    'VggFace2': {'num_classes': 8631},\n",
    "    'MS1M': {'num_classes': 85742}\n",
    "}\n",
    "print(f\"\\nSelected database '{database}' has {db_info[database]['num_classes']} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar args de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments created successfully!\n",
      "Training will save models to: ../../src/models/face-recognition/weights\n",
      "Save directory confirmed: ../../src/models/face-recognition/weights\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(\n",
    "    # Dataset\n",
    "    root=root_path,\n",
    "    database=database,\n",
    "    \n",
    "    # Model\n",
    "    network=network,\n",
    "    classifier=classifier,\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    lr=learning_rate,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    milestones=milestones,\n",
    "    step_size=step_size,\n",
    "    gamma=gamma,\n",
    "    \n",
    "    # Training configuration\n",
    "    save_path=save_path,\n",
    "    num_workers=num_workers,\n",
    "    print_freq=print_freq,\n",
    "    checkpoint=checkpoint_path,\n",
    "    lfw_root=lfw_dataset_path,\n",
    "    \n",
    "    # Distributed training (single GPU setup)\n",
    "    world_size=1,\n",
    "    local_rank=0,\n",
    "    distributed=False,\n",
    "    \n",
    "    # Additional options\n",
    "    use_deterministic_algorithms=False\n",
    ")\n",
    "\n",
    "print(\"Arguments created successfully!\")\n",
    "print(f\"Training will save models to: {args.save_path}\")\n",
    "\n",
    "# Create save directory if it doesn't exist\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "print(f\"Save directory confirmed: {args.save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciar treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 21:44:18 - Loading training data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path verified: ../../data/raw/vggface2_112x112/\n",
      "\n",
      "==================================================\n",
      "STARTING TRAINING\n",
      "==================================================\n",
      "Distributed mode not enabled. Falling back to single process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 21:44:22 - Training samples: 2827910, Validation samples: 309897\n",
      "2025-09-24 21:44:22 - Length of training dataset: 2827910, Number of Identities: 8631\n",
      "2025-09-24 21:44:22 - Training started for mobilenetv2, Classifier: MCP\n",
      "2025-09-24 21:44:23 - Epoch: [0/1][00000/44187] Loss: 21.579, Accuracy: 0.00%, LR: 0.00100 Time: 0.909s\n",
      "2025-09-24 21:51:27 - Epoch: [0/1][10000/44187] Loss: 18.146, Accuracy: 0.00%, LR: 0.00100 Time: 0.042s\n",
      "2025-09-24 21:58:31 - Epoch: [0/1][20000/44187] Loss: 16.035, Accuracy: 0.00%, LR: 0.00100 Time: 0.042s\n",
      "2025-09-24 22:05:35 - Epoch: [0/1][30000/44187] Loss: 14.514, Accuracy: 0.06%, LR: 0.00100 Time: 0.042s\n",
      "2025-09-24 22:12:39 - Epoch: [0/1][40000/44187] Loss: 13.413, Accuracy: 0.23%, LR: 0.00100 Time: 0.042s\n",
      "2025-09-24 22:15:37 - Epoch: [0/1][44186/44187] Loss: 13.041, Accuracy: 0.34%, LR: 0.00100 Time: 0.042s\n",
      "2025-09-24 22:15:37 - Epoch [0/1] Summary: Loss: 13.041, Accuracy: 0.34%, Total Time: 1873.888s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFW - Avaliacao Simplificada (Somente Pares Positivos):\n",
      "Similaridade Media: 0.6279 | Desvio Padrao: 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 22:16:53 - Validation accuracy (VGGFace2 subset): 0.0186\n",
      "2025-09-24 22:16:54 - New best LFW similarity: 0.6279.Model saved to ../../src/models/face-recognition/weights with `_best` postfix.\n",
      "2025-09-24 22:16:54 - Training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING COMPLETED SUCCESSFULLY!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify dataset exists\n",
    "if not os.path.exists(args.root):\n",
    "    print(f\"ERROR: Dataset path does not exist: {args.root}\")\n",
    "    print(\"Please verify the dataset path and try again.\")\n",
    "else:\n",
    "    print(f\"Dataset path verified: {args.root}\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # Start training\n",
    "        main(args)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*50)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nTraining failed with error: {str(e)}\")\n",
    "        print(\"Please check your configuration and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resume training from a checkpoint, uncomment and modify:\n",
    "# checkpoint_path = \"../../weights/mobilenetv2_MCP_last.ckpt\"\n",
    "# args.checkpoint = checkpoint_path\n",
    "# main(args)\n",
    "\n",
    "print(\"To resume training:\")\n",
    "print(\"1. Set checkpoint_path to your .ckpt file\")\n",
    "print(\"2. Update args.checkpoint\")\n",
    "print(\"3. Run main(args)\")\n",
    "print(\"\\nExample checkpoint naming:\")\n",
    "print(f\"Last: {network}_{classifier}_last.ckpt\")\n",
    "print(f\"Best: {network}_{classifier}_best.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
