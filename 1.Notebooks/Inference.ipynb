{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face-Recognition\n",
    "Este notebook tem como objetivo realizar a inferência utilizando pesos de modelos treinados dentre os presentes no framework face-recognition. Aqui é possível: Calcular a similaridade entre duas imagens e extrair embeddings de uma imagem ou em batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações e Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/face_rec_py310/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('../../src/models/face-recognition')\n",
    "from inference import get_network, load_model, compare_faces, extract_features, extract_batch_embeddings\n",
    "from models import (\n",
    "    sphere20,\n",
    "    sphere36,\n",
    "    sphere64,\n",
    "    MobileNetV1,\n",
    "    MobileNetV2,\n",
    "    mobilenet_v3_small,\n",
    "    mobilenet_v3_large\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecionar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "1. sphere20\n",
      "2. sphere36\n",
      "3. sphere64\n",
      "4. mobilenetv1\n",
      "5. mobilenetv2\n",
      "6. mobilenetv3_small\n",
      "7. mobilenetv3_large\n",
      "\n",
      "Selected model: mobilenetv3_large\n"
     ]
    }
   ],
   "source": [
    "# Modelos disponíveis\n",
    "available_models = {\n",
    "    \"sphere20\": sphere20,\n",
    "    \"sphere36\": sphere36,\n",
    "    \"sphere64\": sphere64,\n",
    "    \"mobilenetv1\": MobileNetV1,\n",
    "    \"mobilenetv2\": MobileNetV2,\n",
    "    \"mobilenetv3_small\": mobilenet_v3_small,\n",
    "    \"mobilenetv3_large\": mobilenet_v3_large\n",
    "}\n",
    "\n",
    "print(\"Available models:\")\n",
    "for i, model in enumerate(available_models, 1):\n",
    "    print(f\"{i}. {model}\")\n",
    "\n",
    "# Selecionar modelo\n",
    "model_name = \"mobilenetv3_large\" # Escolha o modelo desejado aqui\n",
    "print(f\"\\nSelected model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: ../../src/models/face-recognition/weights/mobilenetv3_large_5.ckpt\n",
      "Selected model: mobilenetv3_large\n"
     ]
    }
   ],
   "source": [
    "# Configurar caminho do modelo\n",
    "checkpoint_name = \"mobilenetv3_large_5\"\n",
    "model_path = f\"../../src/models/face-recognition/weights/{checkpoint_name}.ckpt\"\n",
    "\n",
    "# Carregar modelo usando a função corrigida do inference.py\n",
    "model = load_model(model_name, model_path, device)\n",
    "\n",
    "print(f\"Model loaded successfully from: {model_path}\")\n",
    "print(f\"Selected model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar duas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: ../../data/raw/lfw/Abdullatif_Sener/Abdullatif_Sener_0001.jpg\n",
      "Image 2: ../../data/raw/lfw/Abdullatif_Sener/Abdullatif_Sener_0002.jpg\n",
      "Similarity Score: 0.6783\n",
      "Same Person: True\n",
      "Threshold: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Configurações de comparação\n",
    "img1_path = \"../../data/raw/lfw/Abdullatif_Sener/Abdullatif_Sener_0001.jpg\"  # Substitua pelo caminho da sua imagem\n",
    "img2_path = \"../../data/raw/lfw/Abdullatif_Sener/Abdullatif_Sener_0002.jpg\"\n",
    "threshold = 0.35  # Ajuste o limiar conforme necessário\n",
    "\n",
    "# Comparar as duas imagens\n",
    "similarity, is_same = compare_faces(model, device, img1_path, img2_path, threshold)\n",
    "\n",
    "print(f\"Image 1: {img1_path}\")\n",
    "print(f\"Image 2: {img2_path}\")\n",
    "print(f\"Similarity Score: {similarity:.4f}\")\n",
    "print(f\"Same Person: {is_same}\")\n",
    "print(f\"Threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrair embedding de uma única imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: ../../data/raw/lfw/Abdullatif_Sener/Abdullatif_Sener_0002.jpg\n",
      "Embedding shape: (512,)\n",
      "Embedding (first 10 values): [-0.6168843  1.9606509 -2.2597706 -1.3064387 -0.894148  -1.5073667\n",
      "  1.4386004 -0.7539237 -1.8357918  1.2179649]\n",
      "Embedding saved to: ../../assets/single_embedding.json\n"
     ]
    }
   ],
   "source": [
    "# Configurações para extração de embedding\n",
    "image_path = \"../../data/raw/lfw/Abdullatif_Sener/Abdullatif_Sener_0002.jpg\"  # Mude para o caminho da sua imagem\n",
    "output_file = \"../../assets/single_embedding.json\"  # Caminho do output\n",
    "\n",
    "# Extrair embedding\n",
    "embedding = extract_features(model, device, image_path)\n",
    "\n",
    "# Preparar dados para salvamento (mesmo formato do batch)\n",
    "image_name = Path(image_path).name\n",
    "embeddings_dict = {\n",
    "    image_name: embedding.tolist()\n",
    "}\n",
    "\n",
    "# Criar diretório se não existir e salvar\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(embeddings_dict, f, indent=2)\n",
    "\n",
    "print(f\"Image: {image_path}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"Embedding (first 10 values): {embedding[:10]}\")\n",
    "print(f\"Embedding saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrair embeddings em batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images to process...\n",
      "✓ Processed and saved: Abdullatif_Sener_0001.jpg -> Abdullatif_Sener_0001.json\n",
      "✓ Processed and saved: Abdullatif_Sener_0002.jpg -> Abdullatif_Sener_0002.json\n",
      "\n",
      "Extraction complete!\n",
      "Processed: 2 images\n",
      "Embeddings saved to individual JSON files in: ../../assets/batch_embeddings\n"
     ]
    }
   ],
   "source": [
    "# Configurações para extração em batch\n",
    "image_folder = \"../../data/raw/lfw/Abdullatif_Sener\"  # Caminho para a pasta com imagens\n",
    "output_folder = \"../../assets/batch_embeddings\"  # Pasta para salvar embeddings individuais\n",
    "\n",
    "# Criar pasta de output se não existir\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Encontrar todas as imagens\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "image_files = []\n",
    "\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(Path(image_folder).glob(f\"*{ext}\"))\n",
    "    image_files.extend(Path(image_folder).glob(f\"*{ext.upper()}\"))\n",
    "\n",
    "print(f\"Found {len(image_files)} images to process...\")\n",
    "\n",
    "# Processar cada imagem e salvar individualmente\n",
    "processed_count = 0\n",
    "for img_path in image_files:\n",
    "    try:\n",
    "        # Extrair embedding\n",
    "        embedding = extract_features(model, device, str(img_path))\n",
    "        \n",
    "        # Criar nome do arquivo JSON (sem extensão da imagem)\n",
    "        image_name_no_ext = img_path.stem  # Nome sem extensão\n",
    "        json_filename = f\"{image_name_no_ext}.json\"\n",
    "        json_path = os.path.join(output_folder, json_filename)\n",
    "        \n",
    "        # Criar dicionário com embedding\n",
    "        embedding_dict = {\n",
    "            img_path.name: embedding.tolist()\n",
    "        }\n",
    "        \n",
    "        # Salvar arquivo JSON individual\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(embedding_dict, f, indent=2)\n",
    "        \n",
    "        processed_count += 1\n",
    "        print(f\"✓ Processed and saved: {img_path.name} -> {json_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {img_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nExtraction complete!\")\n",
    "print(f\"Processed: {processed_count} images\")\n",
    "print(f\"Embeddings saved to individual JSON files in: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
